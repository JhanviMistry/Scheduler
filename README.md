# Local RAG Schedule Assistant

A **local Retrieval-Augmented Generation (RAG) AI agent** that understands your weekly schedule and answers availability questions like:

> *"Am I free on Wednesday from 3â€“5 PM?"*

Everything runs **locally** â€” no cloud dependency â€” using embeddings, SQLite, and a schemaâ€‘validated AI agent.

---

## ğŸš€ Features

* ğŸ“„ Upload a `schedule.txt` or PDF file
* ğŸ” Semantic search over your schedule using embeddings
* ğŸ§  AI agent answers availability questions
* ğŸ“¦ Local SQLite vector database
* ğŸ” Strict schema validation with **pydantic-ai**
* âš¡ FastAPI backend
* ğŸ  Fully local (Ollama-compatible models)

---

## ğŸ§± Architecture Overview

```
User Query
   â†“
Semantic Retrieval (SQLite + embeddings)
   â†“
Relevant Schedule Context
   â†“
AI Agent (pydantic-ai)
   â†“
Structured JSON Response
```

---

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ controller.py      # API routes
â”‚   â”œâ”€â”€ model.py           # Pydantic output schema
â”‚   â”œâ”€â”€ utils.py           # Vector DB, embeddings, retrieval
â”‚   â””â”€â”€ service.py         # File upload & query logic
â”‚
â”œâ”€â”€ ai_model.py         # AI agent + model config
â”œâ”€â”€ main.py             # FastAPI entry point
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html      
â”‚
â”œâ”€â”€ uploads/            # Temporary uploads
â””â”€â”€ knowledge_base.db   # Local SQLite vector store


---

## ğŸ“ Schedule Format (Important)

Your schedule **must follow this format** for accurate results:

```
Wednesday 16:00-18:00 Deep Focus Work
Friday 19:00-21:00 Movie Night
```

Rules:

* One event per line
* Day name spelled fully
* 24â€‘hour time format (`HH:MM-HH:MM`)

---

## ğŸ§ª Example Questions

* `Am I free on Wednesday from 15:00 to 16:00?`
* `Do I have anything Friday evening?`
* `What is my next scheduled task?`

---

## âš™ï¸ Tech Stack

* **FastAPI** â€“ API framework
* **pydantic-ai** â€“ Schemaâ€‘validated AI agent
* **Sentence Transformers** â€“ Local embeddings
* **SQLite** â€“ Vector database
* **Ollama** â€“ Local LLM runtime

---

## â–¶ï¸ Running the Project

### 1ï¸âƒ£ Start Ollama

Make sure Ollama is running:

```bash
ollama serve
```

Pull the model:

```bash
ollama pull llama3.1
```

---

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run the API

```bash
uvicorn app.main:app --reload
```

---

### 4ï¸âƒ£ Upload Schedule

Use `/upload` endpoint to upload `schedule.txt`.

---

### 5ï¸âƒ£ Ask Questions

Send a POST request to `/ask` with your query.

---

## ğŸ§  Why RAG for Scheduling?

Schedules are **semiâ€‘structured**:

* Too rigid for pure ruleâ€‘based systems
* Too precise for pure LLM guessing

RAG lets us:

* Retrieve relevant time blocks
* Let the AI reason *only* over what matters
* Enforce correctness with schemas

---

## ğŸ” Output Schema

The AI always responds in this format:

```json
{
  "availability": "Available" | "Busy",
  "next_slot": "string"
}
```

This guarantees predictable, machineâ€‘readable output.

---

## ğŸ› ï¸ Future Improvements

* â± Deterministic time overlap checking
* ğŸ“… Calendar view / UI
* ğŸ§  Natural language time parsing ("after lunch")
* ğŸ“Š Freeâ€‘slot recommendations

---

## ğŸ‘¤ Author

Built as a **local-first AI agent experiment** to explore RAG, schema enforcement, and agent reliability.

---

âœ¨ *If it runs locally, it runs forever.*
